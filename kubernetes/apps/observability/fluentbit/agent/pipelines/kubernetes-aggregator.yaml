pipeline:
  inputs:
    - name: kafka
      brokers: kafka-cluster-kafka-brokers.databases.svc.cluster.local:9093
      topics: cluster-apps-logs
      rdkafka.client.id: fluent-bit-aggregator
      rdkafka.enable.ssl.certificate.verification: true
      rdkafka.ssl.certificate.location: /fluent-bit/etc/secrets/user.crt
      rdkafka.ssl.key.location: /fluent-bit/etc/secrets/user.key
      rdkafka.ssl.ca.location: /fluent-bit/etc/secrets/ca.crt
      rdkafka.security.protocol: ssl
      format: none
      #rdkafka.fetch.message.max.bytes: 5242880       # 5 MB, must match agent message.max.bytes
      #rdkafka.receive.message.max.bytes: 5242880
      #rdkafka.max.partition.fetch.bytes: 5242880     # 5 MB, also ensures partitions can fetch large messages

  outputs:
    - name: http
      match: '*'
      host: victoria-logs-server.observability.svc.cluster.local
      port: 9428
      uri: /insert/jsonline?_stream_fields=stream,k_namespace_name,k_pod_name,app&_msg_field=log&_time_field=date
      format: json_lines
      json_date_format: iso8601
      compress: gzip
      log_response_payload: false
