---
# Sources
sources:

  kafka:
    type: kafka
    bootstrap_servers: kafka-cluster-kafka-bootstrap.datahub.svc.cluster.local:9093
    topics:
      - k3s-logs-topic
    group_id: k3s-logs-group
    decoding:
      codec: json
    tls:
      enabled: true
      ca_file: /kafka-cluster-ca-cert/ca.crt
      verify_certificate: false
    sasl:
      enabled: false
      mechanism: "SCRAM-SHA-512"
      password: "${KAFKA_PASS}"
      username: "${KAFKA_USER}"

# Transforms
transforms:
  kubernetes_remap:
    type: remap
    inputs: ["kafka"]
    source: |
      # Standardize 'app' index
      .custom_app_name = .pod_labels."app.kubernetes.io/name" || .pod_labels.app || .pod_labels."k8s-app" || "unknown"

      # Standardize 'message' name
      .log = .message

      # Drop pod_labels
      del(.pod_labels)

# Sinks
sinks:
  elasticsearch:
    type: elasticsearch
    #batch:
    #  max_bytes: 2049000
    inputs:
      - kubernetes_remap
    auth:
      strategy: "basic"
      user: "${ELASTICSEARCH__PASSWORD:-ingestion}"
      password: "${ELASTICSEARCH__PASSWORD:-monitor}"
    data_stream:
      # {data_stream.type}-{data_stream.dataset}-{data_stream.namespace}
      # https://www.elastic.co/guide/en/ecs/master/ecs-data_stream.html
      type: logs
      #dataset: "k3s_prod"
      #namespace: "{{ .kubernetes.pod_namespace }}"
      dataset: "k3s"
      namespace: "prod"
    mode: "data_stream"
    bulk:
      action: "create"
    endpoints:
      - "https://elk-es-http.logging.svc.cluster.local:9200"
    tls:
      verify_certificate: false
    encoding:
      except_fields: ["pod_labels"]
